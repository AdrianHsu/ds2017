{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import datasets, linear_model, preprocessing, model_selection, tree\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Spam letter classification\n",
    "# Use the sklearn library to determine whether a letter is spam letter or not.\n",
    "# python classification.py [R, D, S, N] train.csv test.csv\n",
    "# You should generate one “predict.csv” every time we execute the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3999, 58)\n",
      "(602, 58)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('example_train.csv', header=None)\n",
    "test = pd.read_csv('example_test.csv', header=None)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv('example_train.csv', header=None)\n",
    "# test = pd.read_csv('example_test.csv', header=None)\n",
    "# train_X = train.iloc[:, :-1]\n",
    "# train_y = train.iloc[:,-1]\n",
    "# test_X = test\n",
    "\n",
    "dat = pd.read_csv('spambase.csv', header=None)\n",
    "X = dat.iloc[:, :-1]\n",
    "y = dat.iloc[:,-1]\n",
    "train_X, test_X, train_y, test_y = sklearn.model_selection.train_test_split(X, y, test_size = 0.1308, shuffle=True)\n",
    "\n",
    "# scaler = preprocessing.StandardScaler().fit(train_X)\n",
    "# train_X = scaler.transform(train_X)\n",
    "# test_X = scaler.transform(test_X)\n",
    "# https://stackoverflow.com/questions/42263915/using-sklearn-cross-val-score-and-kfolds-to-fit-and-help-predict-model\n",
    "# https://stats.stackexchange.com/questions/52274/how-to-choose-a-predictive-model-after-k-fold-cross-validation\n",
    "\n",
    "# model = lrModel(train_X, train_y)\n",
    "# model = dctModel(train_X, train_y)\n",
    "model = svcModel(train_X, train_y)\n",
    "# model = mlpModel(train_X, train_y) # Neural Network\n",
    "\n",
    "# evaluate\n",
    "print(model.score(train_X, train_y))\n",
    "loss = -cross_val_score(model, train_X, train_y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (loss.mean(), loss.std() * 2))\n",
    "\n",
    "print(model.score(test_X, test_y))\n",
    "loss = -cross_val_score(model, test_X, test_y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (loss.mean(), loss.std() * 2))\n",
    "predicted = model.predict(test_X)\n",
    "ans = []\n",
    "for i in range(len(predicted)):\n",
    "    if predicted[i] < 0.5:\n",
    "        ans.append(0)\n",
    "    else:\n",
    "        ans.append(1)\n",
    "# print(ans)\n",
    "# print(test_y)\n",
    "\n",
    "filename = 'predict.csv'\n",
    "my_df = pd.DataFrame(ans)\n",
    "my_df.to_csv(filename, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrModel(train_X, train_y):\n",
    "\n",
    "    lr = linear_model.LinearRegression(\n",
    "        fit_intercept=True, \n",
    "        normalize=False,\n",
    "        copy_X = True,\n",
    "        n_jobs=1)\n",
    "\n",
    "    lr.fit(train_X, train_y, sample_weight=None)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dctModel(train_X, train_y):\n",
    "\n",
    "    dct = sklearn.tree.DecisionTreeClassifier()\n",
    "    dct.fit(train_X, train_y)\n",
    "    return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svcModel(train_X, train_y):\n",
    "    \n",
    "    svc = sklearn.svm.SVC(\n",
    "        C=1.0, \n",
    "        kernel='rbf',\n",
    "        degree=3,\n",
    "        gamma='auto',\n",
    "        decision_function_shape='ovr')\n",
    "    \n",
    "    svc.fit(train_X, train_y)\n",
    "    \n",
    "    return svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlpModel(train_X, train_y):\n",
    "    mlp = MLPClassifier(hidden_layer_sizes = (15,), max_iter=2000) \n",
    "    mlp.fit(train_X, train_y)\n",
    "    return mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
